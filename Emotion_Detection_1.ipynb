{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Emotion_Detection_1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMjtLW5Et2GI9cw+V9vn+p/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JxB0El3YTeeY"},"source":["**Import Required Libraries**"]},{"cell_type":"code","metadata":{"id":"rIiu3R4bzamb"},"source":["import sys,os\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import keras\n","from keras.models import Sequential \n","from keras.layers import Dense, Dropout, Activation, Flatten  \n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n","from keras.losses import categorical_crossentropy  \n","from keras.optimizers import Adam  \n","from keras.regularizers import l2 \n","from keras.utils import np_utils"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hmVKriscTp9v"},"source":["**Loading, Reading, and Pre-Processing Dataset**"]},{"cell_type":"code","metadata":{"id":"nX7XB-Eiz8dC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606289585542,"user_tz":-330,"elapsed":80122,"user":{"displayName":"Ayush Kesarwani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMXeZA-XzZmPfvV0-ecl_Ga6jzGC_7RFvoCdAr_g=s64","userId":"10610892174047539839"}},"outputId":"5486340e-fe37-477a-9697-f7663e7803c4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RHBkBf-10i_z"},"source":["os.chdir(\"/content/drive/My Drive/Emotion Detection\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C88o_Lmf0v_T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606289590203,"user_tz":-330,"elapsed":1303,"user":{"displayName":"Ayush Kesarwani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMXeZA-XzZmPfvV0-ecl_Ga6jzGC_7RFvoCdAr_g=s64","userId":"10610892174047539839"}},"outputId":"cb398d28-4018-491c-d457-b960878f757b"},"source":["os.listdir()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['archive.zip', 'm.json', 'Detection_Emotion.h5', 'Emotion_Detection_1.ipynb']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"WNsyp0Jd0x41","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606289604597,"user_tz":-330,"elapsed":9648,"user":{"displayName":"Ayush Kesarwani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMXeZA-XzZmPfvV0-ecl_Ga6jzGC_7RFvoCdAr_g=s64","userId":"10610892174047539839"}},"outputId":"4804eae8-4f52-4b8f-e145-2be58cb29e2f"},"source":["df = pd.read_csv(\"archive.zip\")\n","print(df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["       emotion                                             pixels        Usage\n","0            0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...     Training\n","1            0  151 150 147 155 148 133 111 140 170 174 182 15...     Training\n","2            2  231 212 156 164 174 138 161 173 182 200 106 38...     Training\n","3            4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...     Training\n","4            6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...     Training\n","...        ...                                                ...          ...\n","35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n","35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n","35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n","35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n","35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest\n","\n","[35887 rows x 3 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CFEZP00j01t3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606289604599,"user_tz":-330,"elapsed":7319,"user":{"displayName":"Ayush Kesarwani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMXeZA-XzZmPfvV0-ecl_Ga6jzGC_7RFvoCdAr_g=s64","userId":"10610892174047539839"}},"outputId":"d271f5a0-ab2d-4692-b7f6-6dc12fb4b518"},"source":["df.info()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 35887 entries, 0 to 35886\n","Data columns (total 3 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   emotion  35887 non-null  int64 \n"," 1   pixels   35887 non-null  object\n"," 2   Usage    35887 non-null  object\n","dtypes: int64(1), object(2)\n","memory usage: 841.2+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_V8cgNmp05eg"},"source":["X_train,train_y,X_test,test_y=[],[],[],[]  \n","\n","for index, row in df.iterrows():  \n","    val=row['pixels'].split(\" \")  \n","    if 'Training' in row['Usage']:\n","      X_train.append(np.array(val,'float32'))  \n","      train_y.append(row['emotion'])  \n","    elif 'PublicTest' in row['Usage']:  \n","      X_test.append(np.array(val,'float32'))  \n","      test_y.append(row['emotion']) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"As7tSc3G09d8"},"source":["num_features = 64  \n","num_labels = 7  \n","batch_size = 64  \n","epochs = 175\n","width, height = 48, 48  \n","\n","\n","X_train = np.array(X_train,'float32')  \n","train_y = np.array(train_y,'float32')  \n","X_test = np.array(X_test,'float32')  \n","test_y = np.array(test_y,'float32')  \n","\n","train_y=np_utils.to_categorical(train_y, num_classes=num_labels)  \n","test_y=np_utils.to_categorical(test_y, num_classes=num_labels)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TpQHVvMs1Ck-"},"source":["X_train -= np.mean(X_train, axis=0)  \n","X_train /= np.std(X_train, axis=0)  \n","\n","X_test -= np.mean(X_test, axis=0)  \n","X_test /= np.std(X_test, axis=0)  \n","\n","X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)  \n","\n","X_test = X_test.reshape(X_test.shape[0], 48, 48, 1) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CogiK5dPUvoU"},"source":["**Building Model**"]},{"cell_type":"code","metadata":{"id":"vKIZx0_I1GJ_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606289628344,"user_tz":-330,"elapsed":22762,"user":{"displayName":"Ayush Kesarwani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMXeZA-XzZmPfvV0-ecl_Ga6jzGC_7RFvoCdAr_g=s64","userId":"10610892174047539839"}},"outputId":"172f8832-c78f-4b97-f982-c4dc88bc5765"},"source":["model = Sequential()  \n","\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:]), padding='same'))  \n","model.add(Conv2D(64,kernel_size= (3, 3), activation='relu', padding='same'))  \n","model.add(BatchNormalization())  \n","model.add(MaxPooling2D(pool_size=(2,2)))  \n","model.add(Dropout(0.3))  \n","\n","#2nd convolution layer  \n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))  \n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))  \n","model.add(BatchNormalization())  \n","model.add(MaxPooling2D(pool_size=(2,2)))  \n","model.add(Dropout(0.3))  \n","\n","#3rd convolution layer  \n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))  \n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))  \n","model.add(BatchNormalization())  \n","model.add(MaxPooling2D(pool_size=(2,2)))  \n","\n","model.add(Flatten())  \n","\n","#fully connected neural networks  \n","#model.add(Dense(1024, activation='relu'))  \n","#model.add(Dropout(0.2))  \n","#model.add(Dense(1024, activation='relu'))  \n","#model.add(Dropout(0.2))  \n","\n","model.add(Dense(num_labels, activation='softmax'))  \n","\n","model.summary() "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 48, 48, 64)        640       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 48, 48, 64)        36928     \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 48, 48, 64)        256       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 24, 24, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 24, 24, 64)        36928     \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928     \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 24, 24, 64)        256       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 12, 12, 128)       73856     \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 12, 12, 128)       147584    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 12, 12, 128)       512       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 4608)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 32263     \n","=================================================================\n","Total params: 366,151\n","Trainable params: 365,639\n","Non-trainable params: 512\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0VTKhzC8VRKN"},"source":["**Compiling and Training Model**"]},{"cell_type":"code","metadata":{"id":"hZ3r1hfi1QgZ"},"source":["model.compile(loss=categorical_crossentropy,  \n","              optimizer=Adam(),  \n","              metrics=['accuracy'])  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ASF0SP0KZop1"},"source":["class myCallback(tf.keras.callbacks.Callback):\n","        def on_epoch_end(self, epoch, logs={}):\n","            if(logs.get('accuracy')>=1.00):\n","                print(\"Reached 100% accuracy so cancelling training!\")\n","                self.model.stop_training = True\n","\n","callback = myCallback()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o8lb5Oj11X6y","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1603107225860,"user_tz":-330,"elapsed":3614836,"user":{"displayName":"Ayush Kesarwani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiMXeZA-XzZmPfvV0-ecl_Ga6jzGC_7RFvoCdAr_g=s64","userId":"10610892174047539839"}},"outputId":"21c3a824-0b59-438d-b0b1-c64c6d42f3c2"},"source":["model.fit(X_train, train_y, \n","          steps_per_epoch=len(X_train) / batch_size, \n","          batch_size=batch_size,  \n","          epochs=epochs,  \n","          verbose=1,  \n","           callbacks=[callback],\n","          validation_data=(X_test, test_y)\n","          )  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/175\n","449/448 [==============================] - 21s 47ms/step - loss: 1.8567 - accuracy: 0.3392 - val_loss: 1.7904 - val_accuracy: 0.3413\n","Epoch 2/175\n","449/448 [==============================] - 20s 46ms/step - loss: 1.5181 - accuracy: 0.4424 - val_loss: 1.4303 - val_accuracy: 0.4921\n","Epoch 3/175\n","449/448 [==============================] - 20s 45ms/step - loss: 1.3464 - accuracy: 0.5004 - val_loss: 1.3037 - val_accuracy: 0.5127\n","Epoch 4/175\n","449/448 [==============================] - 21s 46ms/step - loss: 1.2346 - accuracy: 0.5389 - val_loss: 1.3261 - val_accuracy: 0.5088\n","Epoch 5/175\n","449/448 [==============================] - 20s 46ms/step - loss: 1.1319 - accuracy: 0.5797 - val_loss: 1.2096 - val_accuracy: 0.5570\n","Epoch 6/175\n","449/448 [==============================] - 21s 46ms/step - loss: 1.0737 - accuracy: 0.6008 - val_loss: 1.1866 - val_accuracy: 0.5770\n","Epoch 7/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.9985 - accuracy: 0.6278 - val_loss: 1.1647 - val_accuracy: 0.5717\n","Epoch 8/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.9328 - accuracy: 0.6566 - val_loss: 1.1829 - val_accuracy: 0.5723\n","Epoch 9/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.8712 - accuracy: 0.6794 - val_loss: 1.2172 - val_accuracy: 0.5740\n","Epoch 10/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.8068 - accuracy: 0.7029 - val_loss: 1.1768 - val_accuracy: 0.5926\n","Epoch 11/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.7480 - accuracy: 0.7270 - val_loss: 1.2087 - val_accuracy: 0.5904\n","Epoch 12/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.6874 - accuracy: 0.7489 - val_loss: 1.2136 - val_accuracy: 0.5965\n","Epoch 13/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.6417 - accuracy: 0.7655 - val_loss: 1.2881 - val_accuracy: 0.5901\n","Epoch 14/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.5789 - accuracy: 0.7911 - val_loss: 1.3005 - val_accuracy: 0.6024\n","Epoch 15/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.5451 - accuracy: 0.8023 - val_loss: 1.3627 - val_accuracy: 0.5834\n","Epoch 16/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.4888 - accuracy: 0.8208 - val_loss: 1.3465 - val_accuracy: 0.6049\n","Epoch 17/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.4543 - accuracy: 0.8348 - val_loss: 1.3999 - val_accuracy: 0.6038\n","Epoch 18/175\n","449/448 [==============================] - 20s 45ms/step - loss: 0.4209 - accuracy: 0.8485 - val_loss: 1.4820 - val_accuracy: 0.5954\n","Epoch 19/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.3861 - accuracy: 0.8607 - val_loss: 1.6021 - val_accuracy: 0.5890\n","Epoch 20/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.3689 - accuracy: 0.8664 - val_loss: 1.5178 - val_accuracy: 0.5993\n","Epoch 21/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.3422 - accuracy: 0.8773 - val_loss: 1.5716 - val_accuracy: 0.5890\n","Epoch 22/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.3305 - accuracy: 0.8799 - val_loss: 1.6905 - val_accuracy: 0.5899\n","Epoch 23/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.3136 - accuracy: 0.8859 - val_loss: 1.5996 - val_accuracy: 0.6052\n","Epoch 24/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.2951 - accuracy: 0.8936 - val_loss: 1.7175 - val_accuracy: 0.5924\n","Epoch 25/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.2752 - accuracy: 0.9032 - val_loss: 1.6579 - val_accuracy: 0.6004\n","Epoch 26/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.2607 - accuracy: 0.9065 - val_loss: 1.7728 - val_accuracy: 0.5982\n","Epoch 27/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.2575 - accuracy: 0.9065 - val_loss: 1.8015 - val_accuracy: 0.5865\n","Epoch 28/175\n","449/448 [==============================] - 20s 45ms/step - loss: 0.2491 - accuracy: 0.9107 - val_loss: 1.7949 - val_accuracy: 0.5918\n","Epoch 29/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.2291 - accuracy: 0.9203 - val_loss: 1.7892 - val_accuracy: 0.5979\n","Epoch 30/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.2292 - accuracy: 0.9172 - val_loss: 1.8955 - val_accuracy: 0.6049\n","Epoch 31/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.2275 - accuracy: 0.9182 - val_loss: 1.9020 - val_accuracy: 0.5910\n","Epoch 32/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.2151 - accuracy: 0.9241 - val_loss: 1.8902 - val_accuracy: 0.6030\n","Epoch 33/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.2083 - accuracy: 0.9259 - val_loss: 1.8927 - val_accuracy: 0.5977\n","Epoch 34/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.2085 - accuracy: 0.9269 - val_loss: 1.8889 - val_accuracy: 0.6041\n","Epoch 35/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.2022 - accuracy: 0.9290 - val_loss: 1.9135 - val_accuracy: 0.6004\n","Epoch 36/175\n","449/448 [==============================] - 20s 45ms/step - loss: 0.1883 - accuracy: 0.9340 - val_loss: 1.9541 - val_accuracy: 0.6060\n","Epoch 37/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1945 - accuracy: 0.9317 - val_loss: 2.0019 - val_accuracy: 0.6043\n","Epoch 38/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1883 - accuracy: 0.9328 - val_loss: 1.9417 - val_accuracy: 0.5974\n","Epoch 39/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1741 - accuracy: 0.9405 - val_loss: 1.9762 - val_accuracy: 0.5974\n","Epoch 40/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1821 - accuracy: 0.9370 - val_loss: 2.1234 - val_accuracy: 0.5901\n","Epoch 41/175\n","449/448 [==============================] - 20s 45ms/step - loss: 0.1657 - accuracy: 0.9421 - val_loss: 2.0580 - val_accuracy: 0.5921\n","Epoch 42/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1768 - accuracy: 0.9378 - val_loss: 2.1744 - val_accuracy: 0.5865\n","Epoch 43/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1611 - accuracy: 0.9440 - val_loss: 2.0404 - val_accuracy: 0.6018\n","Epoch 44/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1720 - accuracy: 0.9402 - val_loss: 2.1080 - val_accuracy: 0.6071\n","Epoch 45/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1598 - accuracy: 0.9452 - val_loss: 2.0619 - val_accuracy: 0.5926\n","Epoch 46/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1523 - accuracy: 0.9466 - val_loss: 2.0883 - val_accuracy: 0.5968\n","Epoch 47/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1521 - accuracy: 0.9476 - val_loss: 2.1487 - val_accuracy: 0.5924\n","Epoch 48/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1515 - accuracy: 0.9484 - val_loss: 2.1605 - val_accuracy: 0.5874\n","Epoch 49/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1503 - accuracy: 0.9479 - val_loss: 2.2089 - val_accuracy: 0.6002\n","Epoch 50/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1464 - accuracy: 0.9508 - val_loss: 2.1147 - val_accuracy: 0.5979\n","Epoch 51/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1418 - accuracy: 0.9510 - val_loss: 2.2313 - val_accuracy: 0.5815\n","Epoch 52/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1470 - accuracy: 0.9504 - val_loss: 2.1788 - val_accuracy: 0.5999\n","Epoch 53/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1338 - accuracy: 0.9542 - val_loss: 2.1339 - val_accuracy: 0.6024\n","Epoch 54/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1360 - accuracy: 0.9540 - val_loss: 2.2155 - val_accuracy: 0.6032\n","Epoch 55/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1302 - accuracy: 0.9560 - val_loss: 2.2032 - val_accuracy: 0.5932\n","Epoch 56/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1372 - accuracy: 0.9528 - val_loss: 2.2022 - val_accuracy: 0.5890\n","Epoch 57/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1346 - accuracy: 0.9541 - val_loss: 2.1667 - val_accuracy: 0.6021\n","Epoch 58/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1314 - accuracy: 0.9550 - val_loss: 2.2446 - val_accuracy: 0.6007\n","Epoch 59/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1298 - accuracy: 0.9560 - val_loss: 2.2614 - val_accuracy: 0.5915\n","Epoch 60/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1226 - accuracy: 0.9585 - val_loss: 2.2066 - val_accuracy: 0.5890\n","Epoch 61/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1236 - accuracy: 0.9583 - val_loss: 2.2095 - val_accuracy: 0.5971\n","Epoch 62/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1218 - accuracy: 0.9607 - val_loss: 2.2142 - val_accuracy: 0.6038\n","Epoch 63/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1197 - accuracy: 0.9594 - val_loss: 2.2424 - val_accuracy: 0.5991\n","Epoch 64/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1091 - accuracy: 0.9628 - val_loss: 2.2398 - val_accuracy: 0.5940\n","Epoch 65/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1179 - accuracy: 0.9608 - val_loss: 2.3311 - val_accuracy: 0.5798\n","Epoch 66/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1151 - accuracy: 0.9624 - val_loss: 2.2754 - val_accuracy: 0.5890\n","Epoch 67/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1264 - accuracy: 0.9585 - val_loss: 2.2798 - val_accuracy: 0.5918\n","Epoch 68/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1119 - accuracy: 0.9634 - val_loss: 2.3058 - val_accuracy: 0.5882\n","Epoch 69/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1113 - accuracy: 0.9635 - val_loss: 2.3107 - val_accuracy: 0.5940\n","Epoch 70/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1106 - accuracy: 0.9646 - val_loss: 2.2894 - val_accuracy: 0.5949\n","Epoch 71/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1072 - accuracy: 0.9640 - val_loss: 2.3135 - val_accuracy: 0.5940\n","Epoch 72/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1116 - accuracy: 0.9625 - val_loss: 2.3210 - val_accuracy: 0.5940\n","Epoch 73/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1056 - accuracy: 0.9659 - val_loss: 2.2949 - val_accuracy: 0.5982\n","Epoch 74/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1021 - accuracy: 0.9659 - val_loss: 2.3719 - val_accuracy: 0.5968\n","Epoch 75/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1037 - accuracy: 0.9659 - val_loss: 2.3883 - val_accuracy: 0.5963\n","Epoch 76/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.1080 - accuracy: 0.9638 - val_loss: 2.3795 - val_accuracy: 0.5899\n","Epoch 77/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1062 - accuracy: 0.9649 - val_loss: 2.3508 - val_accuracy: 0.5910\n","Epoch 78/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0955 - accuracy: 0.9689 - val_loss: 2.3829 - val_accuracy: 0.5949\n","Epoch 79/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0987 - accuracy: 0.9672 - val_loss: 2.4050 - val_accuracy: 0.5826\n","Epoch 80/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1007 - accuracy: 0.9677 - val_loss: 2.3465 - val_accuracy: 0.5952\n","Epoch 81/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0976 - accuracy: 0.9687 - val_loss: 2.3163 - val_accuracy: 0.5963\n","Epoch 82/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1010 - accuracy: 0.9681 - val_loss: 2.3415 - val_accuracy: 0.5882\n","Epoch 83/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0964 - accuracy: 0.9682 - val_loss: 2.4223 - val_accuracy: 0.5865\n","Epoch 84/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0922 - accuracy: 0.9701 - val_loss: 2.4284 - val_accuracy: 0.6041\n","Epoch 85/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0973 - accuracy: 0.9681 - val_loss: 2.3537 - val_accuracy: 0.6041\n","Epoch 86/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0914 - accuracy: 0.9706 - val_loss: 2.3283 - val_accuracy: 0.6038\n","Epoch 87/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0881 - accuracy: 0.9712 - val_loss: 2.3613 - val_accuracy: 0.5954\n","Epoch 88/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.1014 - accuracy: 0.9678 - val_loss: 2.4222 - val_accuracy: 0.5901\n","Epoch 89/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0882 - accuracy: 0.9722 - val_loss: 2.3874 - val_accuracy: 0.5977\n","Epoch 90/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0875 - accuracy: 0.9715 - val_loss: 2.4285 - val_accuracy: 0.5949\n","Epoch 91/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0880 - accuracy: 0.9724 - val_loss: 2.3932 - val_accuracy: 0.5988\n","Epoch 92/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0895 - accuracy: 0.9716 - val_loss: 2.4383 - val_accuracy: 0.5954\n","Epoch 93/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0919 - accuracy: 0.9692 - val_loss: 2.3882 - val_accuracy: 0.5993\n","Epoch 94/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0868 - accuracy: 0.9722 - val_loss: 2.4348 - val_accuracy: 0.5968\n","Epoch 95/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0862 - accuracy: 0.9733 - val_loss: 2.4100 - val_accuracy: 0.6013\n","Epoch 96/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0869 - accuracy: 0.9722 - val_loss: 2.3346 - val_accuracy: 0.6013\n","Epoch 97/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0874 - accuracy: 0.9723 - val_loss: 2.3942 - val_accuracy: 0.6110\n","Epoch 98/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0841 - accuracy: 0.9725 - val_loss: 2.3957 - val_accuracy: 0.5915\n","Epoch 99/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0902 - accuracy: 0.9703 - val_loss: 2.3519 - val_accuracy: 0.6035\n","Epoch 100/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0833 - accuracy: 0.9738 - val_loss: 2.3758 - val_accuracy: 0.6063\n","Epoch 101/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0768 - accuracy: 0.9758 - val_loss: 2.4069 - val_accuracy: 0.6055\n","Epoch 102/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0827 - accuracy: 0.9741 - val_loss: 2.4630 - val_accuracy: 0.5993\n","Epoch 103/175\n","449/448 [==============================] - 20s 45ms/step - loss: 0.0805 - accuracy: 0.9744 - val_loss: 2.5062 - val_accuracy: 0.6055\n","Epoch 104/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0763 - accuracy: 0.9765 - val_loss: 2.5178 - val_accuracy: 0.5938\n","Epoch 105/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0800 - accuracy: 0.9758 - val_loss: 2.4403 - val_accuracy: 0.6052\n","Epoch 106/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0806 - accuracy: 0.9739 - val_loss: 2.4415 - val_accuracy: 0.5965\n","Epoch 107/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0758 - accuracy: 0.9763 - val_loss: 2.3893 - val_accuracy: 0.5985\n","Epoch 108/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0811 - accuracy: 0.9739 - val_loss: 2.4333 - val_accuracy: 0.5991\n","Epoch 109/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0767 - accuracy: 0.9759 - val_loss: 2.4260 - val_accuracy: 0.5910\n","Epoch 110/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0752 - accuracy: 0.9751 - val_loss: 2.4478 - val_accuracy: 0.5910\n","Epoch 111/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0760 - accuracy: 0.9761 - val_loss: 2.4458 - val_accuracy: 0.5952\n","Epoch 112/175\n","449/448 [==============================] - 21s 47ms/step - loss: 0.0770 - accuracy: 0.9757 - val_loss: 2.4142 - val_accuracy: 0.5963\n","Epoch 113/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0760 - accuracy: 0.9760 - val_loss: 2.4680 - val_accuracy: 0.5843\n","Epoch 114/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0765 - accuracy: 0.9751 - val_loss: 2.4400 - val_accuracy: 0.5991\n","Epoch 115/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0749 - accuracy: 0.9770 - val_loss: 2.5477 - val_accuracy: 0.5921\n","Epoch 116/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0699 - accuracy: 0.9780 - val_loss: 2.4813 - val_accuracy: 0.5993\n","Epoch 117/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0739 - accuracy: 0.9780 - val_loss: 2.5207 - val_accuracy: 0.5988\n","Epoch 118/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0753 - accuracy: 0.9760 - val_loss: 2.4967 - val_accuracy: 0.5918\n","Epoch 119/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0767 - accuracy: 0.9762 - val_loss: 2.4891 - val_accuracy: 0.5921\n","Epoch 120/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0708 - accuracy: 0.9772 - val_loss: 2.5227 - val_accuracy: 0.5991\n","Epoch 121/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0702 - accuracy: 0.9786 - val_loss: 2.4075 - val_accuracy: 0.6007\n","Epoch 122/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0723 - accuracy: 0.9766 - val_loss: 2.4571 - val_accuracy: 0.6004\n","Epoch 123/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0724 - accuracy: 0.9773 - val_loss: 2.5567 - val_accuracy: 0.5960\n","Epoch 124/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0675 - accuracy: 0.9789 - val_loss: 2.4151 - val_accuracy: 0.6082\n","Epoch 125/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0692 - accuracy: 0.9784 - val_loss: 2.4698 - val_accuracy: 0.6013\n","Epoch 126/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0727 - accuracy: 0.9782 - val_loss: 2.4374 - val_accuracy: 0.6032\n","Epoch 127/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0667 - accuracy: 0.9803 - val_loss: 2.4918 - val_accuracy: 0.5999\n","Epoch 128/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0684 - accuracy: 0.9800 - val_loss: 2.5180 - val_accuracy: 0.5963\n","Epoch 129/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0715 - accuracy: 0.9778 - val_loss: 2.4824 - val_accuracy: 0.6057\n","Epoch 130/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0702 - accuracy: 0.9785 - val_loss: 2.4656 - val_accuracy: 0.5963\n","Epoch 131/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0632 - accuracy: 0.9814 - val_loss: 2.5017 - val_accuracy: 0.6116\n","Epoch 132/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0692 - accuracy: 0.9784 - val_loss: 2.4782 - val_accuracy: 0.5982\n","Epoch 133/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0661 - accuracy: 0.9800 - val_loss: 2.5537 - val_accuracy: 0.6018\n","Epoch 134/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0658 - accuracy: 0.9794 - val_loss: 2.5170 - val_accuracy: 0.6004\n","Epoch 135/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0631 - accuracy: 0.9809 - val_loss: 2.5300 - val_accuracy: 0.6016\n","Epoch 136/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0664 - accuracy: 0.9790 - val_loss: 2.5197 - val_accuracy: 0.5968\n","Epoch 137/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0653 - accuracy: 0.9793 - val_loss: 2.5825 - val_accuracy: 0.5915\n","Epoch 138/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0670 - accuracy: 0.9788 - val_loss: 2.4759 - val_accuracy: 0.6060\n","Epoch 139/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0685 - accuracy: 0.9796 - val_loss: 2.5147 - val_accuracy: 0.5985\n","Epoch 140/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0603 - accuracy: 0.9820 - val_loss: 2.5310 - val_accuracy: 0.5952\n","Epoch 141/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0656 - accuracy: 0.9797 - val_loss: 2.5063 - val_accuracy: 0.6035\n","Epoch 142/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0694 - accuracy: 0.9783 - val_loss: 2.4645 - val_accuracy: 0.6046\n","Epoch 143/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0671 - accuracy: 0.9801 - val_loss: 2.4294 - val_accuracy: 0.5991\n","Epoch 144/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0610 - accuracy: 0.9822 - val_loss: 2.5173 - val_accuracy: 0.5977\n","Epoch 145/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0598 - accuracy: 0.9806 - val_loss: 2.4935 - val_accuracy: 0.5979\n","Epoch 146/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0579 - accuracy: 0.9821 - val_loss: 2.5222 - val_accuracy: 0.6041\n","Epoch 147/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0634 - accuracy: 0.9815 - val_loss: 2.5418 - val_accuracy: 0.5977\n","Epoch 148/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0600 - accuracy: 0.9822 - val_loss: 2.5331 - val_accuracy: 0.6043\n","Epoch 149/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0594 - accuracy: 0.9824 - val_loss: 2.5022 - val_accuracy: 0.5991\n","Epoch 150/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0617 - accuracy: 0.9816 - val_loss: 2.5150 - val_accuracy: 0.6080\n","Epoch 151/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0591 - accuracy: 0.9823 - val_loss: 2.5346 - val_accuracy: 0.5999\n","Epoch 152/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0661 - accuracy: 0.9801 - val_loss: 2.4523 - val_accuracy: 0.6021\n","Epoch 153/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0583 - accuracy: 0.9813 - val_loss: 2.5202 - val_accuracy: 0.6032\n","Epoch 154/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0614 - accuracy: 0.9821 - val_loss: 2.5766 - val_accuracy: 0.6018\n","Epoch 155/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0573 - accuracy: 0.9832 - val_loss: 2.4998 - val_accuracy: 0.5988\n","Epoch 156/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0572 - accuracy: 0.9835 - val_loss: 2.5666 - val_accuracy: 0.6057\n","Epoch 157/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0613 - accuracy: 0.9823 - val_loss: 2.4897 - val_accuracy: 0.6010\n","Epoch 158/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0582 - accuracy: 0.9838 - val_loss: 2.5121 - val_accuracy: 0.6041\n","Epoch 159/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0624 - accuracy: 0.9811 - val_loss: 2.4837 - val_accuracy: 0.6069\n","Epoch 160/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0585 - accuracy: 0.9827 - val_loss: 2.6001 - val_accuracy: 0.6102\n","Epoch 161/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0590 - accuracy: 0.9823 - val_loss: 2.5550 - val_accuracy: 0.6066\n","Epoch 162/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0581 - accuracy: 0.9826 - val_loss: 2.5223 - val_accuracy: 0.6007\n","Epoch 163/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0589 - accuracy: 0.9826 - val_loss: 2.5876 - val_accuracy: 0.5991\n","Epoch 164/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0530 - accuracy: 0.9836 - val_loss: 2.5902 - val_accuracy: 0.6010\n","Epoch 165/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0575 - accuracy: 0.9840 - val_loss: 2.5464 - val_accuracy: 0.6030\n","Epoch 166/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0563 - accuracy: 0.9840 - val_loss: 2.5730 - val_accuracy: 0.6030\n","Epoch 167/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0589 - accuracy: 0.9829 - val_loss: 2.4697 - val_accuracy: 0.6027\n","Epoch 168/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0553 - accuracy: 0.9842 - val_loss: 2.5325 - val_accuracy: 0.5993\n","Epoch 169/175\n","449/448 [==============================] - 20s 46ms/step - loss: 0.0577 - accuracy: 0.9838 - val_loss: 2.6346 - val_accuracy: 0.5996\n","Epoch 170/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0550 - accuracy: 0.9845 - val_loss: 2.5300 - val_accuracy: 0.6063\n","Epoch 171/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0528 - accuracy: 0.9850 - val_loss: 2.5102 - val_accuracy: 0.6071\n","Epoch 172/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0583 - accuracy: 0.9825 - val_loss: 2.5085 - val_accuracy: 0.6027\n","Epoch 173/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0561 - accuracy: 0.9840 - val_loss: 2.5149 - val_accuracy: 0.6071\n","Epoch 174/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0588 - accuracy: 0.9822 - val_loss: 2.4584 - val_accuracy: 0.6066\n","Epoch 175/175\n","449/448 [==============================] - 21s 46ms/step - loss: 0.0479 - accuracy: 0.9857 - val_loss: 2.5053 - val_accuracy: 0.6069\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f643d069828>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"AJ85iiv0VYG4"},"source":["**Save Model**"]},{"cell_type":"code","metadata":{"id":"cm95vbYu1h6K"},"source":["m_json = model.to_json()  \n","with open(\"m.json\", \"w\") as json_file:  \n","    json_file.write(m_json)  \n","model.save_weights(\"Detection_Emotion.h5\") "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C1aQsmjfWEEU"},"source":["## After Saving the model, I’ll use Opencv to predict Emotions in Real-Time. But first of all, download the saved weights and model. We’ll work on our local machines now. why?? Because VideoCapture doesn’t work in google colab, in other words, using a webcam in google colab isn’t easy.\n","\n","\n","Go to Real_Time_Detection.py file."]}]}